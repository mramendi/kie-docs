[id='integration-kafka-con_{context}']
= Sending and receiving {KAFKA} messages in a business process

ifdef::JBPM,DROOLS,OP[]
{KAFKA}
endif::JBPM,DROOLS,OP[]
ifdef::PAM,DM[]
{KAFKA}, based on Apache Kafka,
endif::PAM,DM[]
is a streaming platform. It passes messages, sorted into topics, between applications in a software environment.

You can create business processes using {PRODUCT} that send and receive {KAFKA} messages in the following ways:

* Create a start event or intermediate catch event of the type _message_ or _signal_. The {KIE_SERVER} automatically subsribes to the {KAFKA} topic that is defined in the message or signal. A message triggers the event. The event can pass the content of the message to the subsequent node in the process.

* Create an end event or intermediate throw event of the type _message_ or _signal_. When the process triggers the event, the {KIE_SERVER} sends a {KAFKA} message in the topic that is defined in the message or signal. The message contains the data that is configured in the event. 

* Add the `KafkaPublishMessages` custom task to the process. This task does not require the {KIE_SERVER} Kafka capability. However, it is significantly more complicated to configure than signal or message events. 

* Configure your service and the {KIE_SERVER} to emit {KAFKA} messages about every completed process, case, and task when transactions are committed.

